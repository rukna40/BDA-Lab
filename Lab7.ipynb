{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777f60cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 10:39:48 WARN Utils: Your hostname, mahe-HP-Z1-G9-Tower-Desktop-PC resolves to a loopback address: 127.0.1.1; using 172.16.57.86 instead (on interface eno1)\n",
      "24/09/16 10:39:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/16 10:39:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Lab7\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e55655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:=========>                                               (3 + 15) / 18]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.option(\"inferSchema\", True).option(\"header\", False).csv(\"kddcup.data_10_percent_corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5e6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 10:39:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(duration=0, protocol_type='tcp', service='http', flag='SF', src_bytes=181, dst_bytes=5450, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=8, srv_count=8, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=9, dst_host_srv_count=9, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.11, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0, label='normal.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [ \"duration\", \"protocol_type\", \"service\", \"flag\",\"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \n",
    "                \"urgent\",\"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\"root_shell\", \"su_attempted\", \n",
    "                \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \n",
    "                \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \n",
    "                \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \n",
    "                \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \n",
    "                \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \n",
    "                \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "\n",
    "data = data.toDF(*column_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1a4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans, KMeansModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "def kmeans(data, k):\n",
    "\n",
    "    assembler = VectorAssembler().setInputCols(numeric.columns[:-1]).setOutputCol(\"featureVector\")\n",
    "    \n",
    "    scaler = StandardScaler().setInputCol(\"featureVector\").setOutputCol(\"scaledFeatureVector\") \\\n",
    "    .setWithStd(True).setWithMean(False)\n",
    "\n",
    "    kmeans = KMeans().setK(k).setMaxIter(40).setTol(1.0e-5).setPredictionCol(\"cluster\") \\\n",
    "    .setFeaturesCol(\"scaledFeatureVector\")\n",
    "\n",
    "    pipeline = Pipeline().setStages([assembler, scaler, kmeans])\n",
    "\n",
    "    model = pipeline.fit(numeric)\n",
    "\n",
    "    kmeans_model = model.stages[-1]\n",
    "\n",
    "    training_cost = kmeans_model.summary.trainingCost\n",
    "\n",
    "    return training_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db74c04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 10:40:28 WARN CacheManager: Asked to cache already cached data.\n",
      "24/09/16 10:40:32 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 3292760.0271574617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 978756.2232713241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:======>                                                (2 + 16) / 18]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 554460.9308034047\n",
      "80 385098.24050851556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 280:============>                                          (4 + 14) / 18]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 292475.13841435744\n"
     ]
    }
   ],
   "source": [
    "numeric = data.drop(\"protocol_type\", \"service\", \"flag\").cache()\n",
    "\n",
    "for k in list(range(20,101,20)):\n",
    "    print(k, kmeans(numeric, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d923df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
