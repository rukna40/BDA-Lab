{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 21:15:00 WARN Utils: Your hostname, ankurPC resolves to a loopback address: 127.0.1.1; using 10.87.1.9 instead (on interface wlp0s20f3)\n",
      "24/11/03 21:15:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/03 21:15:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Lab7\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"stock_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df.select(\"Close\").rdd.flatMap(lambda x: x).collect()\n",
    "returns = np.diff(returns) / returns[:-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = np.mean(returns)\n",
    "volatility = np.std(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(start, drift, volatility, num=252, sims=1000):\n",
    "    results = []\n",
    "    for _ in range(sims):\n",
    "        prices = [start]\n",
    "        for _ in range(num):\n",
    "            shock = np.random.normal(0, 1)  \n",
    "            price = prices[-1] * np.exp(drift + volatility * shock)\n",
    "            prices.append(price)\n",
    "        results.append(prices)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = df.select(\"Close\").tail(1)[0][0]  \n",
    "steps = 252 \n",
    "sims = 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.sparkContext.parallelize([start] * sims).map(\n",
    "    lambda start: monte_carlo(start, drift, volatility, steps, 1)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1          2          3          4          5    \\\n",
      "0  52.950000  52.950000  52.950000  52.950000  52.950000  52.950000   \n",
      "1  53.070409  53.070409  53.070409  53.070409  53.070409  53.070409   \n",
      "2  53.191092  53.191092  53.191092  53.191092  53.191092  53.191092   \n",
      "3  53.312050  53.312050  53.312050  53.312050  53.312050  53.312050   \n",
      "4  53.433282  53.433282  53.433282  53.433282  53.433282  53.433282   \n",
      "\n",
      "         6          7          8          9    ...        990        991  \\\n",
      "0  52.950000  52.950000  52.950000  52.950000  ...  52.950000  52.950000   \n",
      "1  53.070409  53.070409  53.070409  53.070409  ...  53.070409  53.070409   \n",
      "2  53.191092  53.191092  53.191092  53.191092  ...  53.191092  53.191092   \n",
      "3  53.312050  53.312050  53.312050  53.312050  ...  53.312050  53.312050   \n",
      "4  53.433282  53.433282  53.433282  53.433282  ...  53.433282  53.433282   \n",
      "\n",
      "         992        993        994        995        996        997  \\\n",
      "0  52.950000  52.950000  52.950000  52.950000  52.950000  52.950000   \n",
      "1  53.070409  53.070409  53.070409  53.070409  53.070409  53.070409   \n",
      "2  53.191092  53.191092  53.191092  53.191092  53.191092  53.191092   \n",
      "3  53.312050  53.312050  53.312050  53.312050  53.312050  53.312050   \n",
      "4  53.433282  53.433282  53.433282  53.433282  53.433282  53.433282   \n",
      "\n",
      "         998        999  \n",
      "0  52.950000  52.950000  \n",
      "1  53.070409  53.070409  \n",
      "2  53.191092  53.191092  \n",
      "3  53.312050  53.312050  \n",
      "4  53.433282  53.433282  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "simulated_prices = results.collect()\n",
    "simulated_prices_df = pd.DataFrame(simulated_prices).T\n",
    "# simulated_prices_df.columns = [f'Simulation_{i+1}' for i in range(sims)]\n",
    "print(simulated_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
