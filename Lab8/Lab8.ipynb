{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Lab7\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"stock_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df.select(\"Close\").rdd.flatMap(lambda x: x).collect()\n",
    "returns = np.diff(returns) / returns[:-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = np.mean(returns)\n",
    "volatility = np.std(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(start_price, drift, volatility, num_steps=252, num_simulations=1000):\n",
    "    results = []\n",
    "    for _ in range(num_simulations):\n",
    "        price_series = [start_price]\n",
    "        for _ in range(num_steps):\n",
    "            shock = np.random.normal(0, 1)  \n",
    "            price = price_series[-1] * np.exp(drift + volatility * shock)\n",
    "            price_series.append(price)\n",
    "        results.append(price_series)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_price = df.select(\"Close\").tail(1)[0][0]  \n",
    "num_steps = 252 \n",
    "num_simulations = 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rdd = spark.sparkContext.parallelize([start_price] * num_simulations).map(\n",
    "    lambda start: monte_carlo_simulation(start, drift, volatility, num_steps, 1)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Simulation_1  Simulation_2  Simulation_3  Simulation_4  Simulation_5  \\\n",
      "0     52.950000     52.950000     52.950000     52.950000     52.950000   \n",
      "1     53.070409     53.070409     53.070409     53.070409     53.070409   \n",
      "2     53.191092     53.191092     53.191092     53.191092     53.191092   \n",
      "3     53.312050     53.312050     53.312050     53.312050     53.312050   \n",
      "4     53.433282     53.433282     53.433282     53.433282     53.433282   \n",
      "\n",
      "   Simulation_6  Simulation_7  Simulation_8  Simulation_9  Simulation_10  ...  \\\n",
      "0     52.950000     52.950000     52.950000     52.950000      52.950000  ...   \n",
      "1     53.070409     53.070409     53.070409     53.070409      53.070409  ...   \n",
      "2     53.191092     53.191092     53.191092     53.191092      53.191092  ...   \n",
      "3     53.312050     53.312050     53.312050     53.312050      53.312050  ...   \n",
      "4     53.433282     53.433282     53.433282     53.433282      53.433282  ...   \n",
      "\n",
      "   Simulation_991  Simulation_992  Simulation_993  Simulation_994  \\\n",
      "0       52.950000       52.950000       52.950000       52.950000   \n",
      "1       53.070409       53.070409       53.070409       53.070409   \n",
      "2       53.191092       53.191092       53.191092       53.191092   \n",
      "3       53.312050       53.312050       53.312050       53.312050   \n",
      "4       53.433282       53.433282       53.433282       53.433282   \n",
      "\n",
      "   Simulation_995  Simulation_996  Simulation_997  Simulation_998  \\\n",
      "0       52.950000       52.950000       52.950000       52.950000   \n",
      "1       53.070409       53.070409       53.070409       53.070409   \n",
      "2       53.191092       53.191092       53.191092       53.191092   \n",
      "3       53.312050       53.312050       53.312050       53.312050   \n",
      "4       53.433282       53.433282       53.433282       53.433282   \n",
      "\n",
      "   Simulation_999  Simulation_1000  \n",
      "0       52.950000        52.950000  \n",
      "1       53.070409        53.070409  \n",
      "2       53.191092        53.191092  \n",
      "3       53.312050        53.312050  \n",
      "4       53.433282        53.433282  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "simulated_prices = results_rdd.collect()\n",
    "simulated_prices_df = pd.DataFrame(simulated_prices).T\n",
    "simulated_prices_df.columns = [f'Simulation_{i+1}' for i in range(num_simulations)]\n",
    "print(simulated_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
